{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from matplotlib import pyplot as plt \n",
    "import math\n",
    "import scipy\n",
    "import pickle as pkl\n",
    "import re\n",
    "import datetime\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "# Define el directorio predeterminado\n",
    "directorio_predeterminado = 'C:/Users/20960898940/Documents/metricas/data/raw'\n",
    "\n",
    "# Cambiar al directorio predeterminado\n",
    "os.chdir(directorio_predeterminado)\n",
    "\n",
    "# Ahora el directorio predeterminado es el nuevo directorio de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuarios que mandaron @test_on @test_off @reset_user INCORPORAR LOS NUEVOS INTENT PARA TESTEO QUE SE AGREGARON EN FEBRERO DEL 2024\n",
    "\n",
    "testers=pd.read_csv('testers.csv')\n",
    "#testers=testers.f0_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_ne='PLBWX5XYGQ2B3GP7IN8Q-nml045fna3@b.m-1669990832420'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesage metrics (mensajes)\n",
    "#mm=pd.read_csv('mensajes.csv',sep=\",\")\n",
    "\n",
    "# Definimos el tamaño del chunk, por ejemplo, 100,000 filas por chunk\n",
    "chunksize = 100000\n",
    "\n",
    "# Se crea una lista vacía para almacenar los DataFrames\n",
    "chunk_list_m = []\n",
    "\n",
    "# Lee el archivo CSV en chunks\n",
    "for chunk in pd.read_csv('mensajes.csv', chunksize=chunksize):\n",
    "    \n",
    "    # Agregamos el chunk procesado a la lista\n",
    "    chunk_list_m.append(chunk)\n",
    "\n",
    "# Combinamos en un solo DataFrame\n",
    "mm = pd.concat(chunk_list_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificaciones necesesarias al campo creation_time segun la fuente de origen (Bq o Athena)\n",
    "\n",
    "mm.creation_time=pd.to_datetime(mm.creation_time)\n",
    "\n",
    "#mm.creation_time = pd.to_datetime(str(mm.creation_time)[10:30])\n",
    "\n",
    "mm.creation_time=mm.creation_time.dt.tz_localize(None)\n",
    "\n",
    "#mm = mm.rename(columns = {\"vars_value\": \"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación de fecha mínima o de rango de fecha y hora\n",
    "\n",
    "mm1=mm[mm['creation_time']>=np.datetime64('2024-02-19 13:00:00') ]\n",
    "#mm1 = mm[(mm['creation_time'] >= np.datetime64('2024-02-23 17:00:00')) & (mm['creation_time'] <= np.datetime64('2024-02-24 18:00:00'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm1.rule_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte la columna 'creation_time' de mm1 al formato de fecha y hora.\n",
    "mm1.creation_time = pd.to_datetime(mm1.creation_time)\n",
    "\n",
    "# Redondea hacia arriba la columna 'creation_time' al segundo más cercano.\n",
    "mm1.creation_time = mm1.creation_time.dt.ceil('s')\n",
    "\n",
    "# Elimina filas duplicadas basadas en las columnas especificadas.\n",
    "mm1.drop_duplicates(['session_id', 'creation_time', 'msg_from', 'rule_name'], inplace=True)\n",
    "\n",
    "# Crea una nueva columna 'usuario' que toma los primeros 20 caracteres de la columna 'session_id'.\n",
    "mm1['usuario'] = mm1.session_id.str[:20]\n",
    "\n",
    "# Filtra las filas donde el valor de 'usuario' no está en la lista de testers.\n",
    "mm1 = mm1[~mm1.usuario.isin(testers)]\n",
    "\n",
    "# Reinicia los índices del DataFrame después de realizar las operaciones anteriores y descarta los índices anteriores.\n",
    "mm1.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm1.usuario.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el tamaño del chunk, por ejemplo, 100,000 filas por chunk\n",
    "chunksize = 100000\n",
    "\n",
    "# Se crea una lista vacía para almacenar los DataFrames\n",
    "chunk_list_s = []\n",
    "\n",
    "# Lee el archivo CSV en chunks\n",
    "for chunk in pd.read_csv('clicks.csv', chunksize=chunksize):\n",
    "    \n",
    "    # Agregamos el chunk procesado a la lista\n",
    "    chunk_list_s.append(chunk)\n",
    "\n",
    "# Combinamos en un solo DataFrame\n",
    "search = pd.concat(chunk_list_s)\n",
    "\n",
    "# Guarda el DataFrame completo como un nuevo archivo CSV (si se necesita)\n",
    "#full_df.to_csv('clicks_combined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search + response = clicks\n",
    "\n",
    "# Lee el archivo CSV y carga los datos en el DataFrame 'search'.\n",
    "#search=pd.read_csv('clicks.csv',sep=\",\")\n",
    "\n",
    "# Elimina filas duplicadas basadas en las columnas especificadas en el DataFrame 'search'.\n",
    "search.drop_duplicates(['session_id', 'ts', 'id', 'message', 'mostrado', 'response_message'], inplace=True)\n",
    "\n",
    "#####################################################\n",
    "#EN ESTE LUGAR ESTARIA BUENO PROBAR EL MISMO REDONDEO DEL SEGUNDO EN TS PARA EVITAR EL PROBLEMA QUE TUVIMOS CON LA CANTIDAD DE CARACTERAS\n",
    "\n",
    "# Redondea hacia arriba la columna 'creation_time' al segundo más cercano.\n",
    "mm1.creation_time = mm1.creation_time.dt.ceil('s')\n",
    "# Convierte la columna 'ts' (timestamp) de 'search' al formato de fecha y hora.\n",
    "search.ts=pd.to_datetime(search.ts)\n",
    "####################################################\n",
    "\n",
    "# Crea una nueva columna 'usuario' que toma los primeros 20 caracteres de la columna 'session_id'.\n",
    "search['usuario']=search.session_id.str[:20]\n",
    "\n",
    "# Filtra las filas donde el valor de 'usuario' no está en la lista de testers.\n",
    "search=search[~search.usuario.isin(testers)]\n",
    "\n",
    "# Filtra las filas en las que la columna 'mostrado' es igual a la columna 'response_intent_id' con la condición 'RuleBuilder:'.\n",
    "# Luego, elimina filas duplicadas basadas en la columna 'id' del resultado y almacena el resultado en 'searchcl'.\n",
    "searchcl=search['RuleBuilder:'+search.mostrado==search.response_intent_id].drop_duplicates('id')\n",
    "\n",
    "# Crea una nueva columna 'fecha' en 'search' que contiene solo la parte de la fecha de la columna 'ts'.\n",
    "search['fecha']=search.ts.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-buttons (botones)\n",
    "#one=pd.read_csv('botones.csv',sep=\",\")\n",
    "\n",
    "# Definimos el tamaño del chunk, por ejemplo, 100,000 filas por chunk\n",
    "chunksize = 100000\n",
    "\n",
    "# Se crea una lista vacía para almacenar los DataFrames\n",
    "chunk_list_b= []\n",
    "\n",
    "# Lee el archivo CSV en chunks\n",
    "for chunk in pd.read_csv('botones.csv', chunksize=chunksize):\n",
    "    \n",
    "    # Agregamos el chunk procesado a la lista\n",
    "    chunk_list_b.append(chunk)\n",
    "\n",
    "# Combinamos en un solo DataFrame\n",
    "one = pd.concat(chunk_list_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento de datos en el DataFrame 'one':  ONESHOTS\n",
    "\n",
    "# Crea una nueva columna 'usuario' en el DataFrame 'one', que toma los primeros 20 caracteres de la columna 'session_id'.\n",
    "one['usuario'] = one.session_id.str[:20]\n",
    "\n",
    "# Filtra las filas donde el valor de 'usuario' no está en la lista de testers.\n",
    "one = one[~one.usuario.isin(testers)]\n",
    "\n",
    "# Filtra las filas en el DataFrame 'one' donde 'one_shot' es True y 'type' es 'oneShot' o 'oneShotSearch'.\n",
    "os = one[np.logical_and(one.one_shot == True, one.type.isin(['oneShot', 'oneShotSearch']))]\n",
    "\n",
    "# Convierte la columna 'ts' (timestamp) de 'os' al formato de fecha y hora. HABRIA QUE REDONDEAR LSO SEGUNDOS POR LAS DUDAS TAMBIEN?\n",
    "os.ts = pd.to_datetime(os.ts)\n",
    "\n",
    "# Crea una nueva columna 'fecha' en 'os' que contiene solo la parte de la fecha de la columna 'ts'.\n",
    "os['fecha'] = os.ts.dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos el csv con la lista de los intents mostrables (tambien aparece como showable)\n",
    "\n",
    "mos=pd.read_csv('Actualizacion_Lista_Blanca.csv')\n",
    "# Elimina los espacios en blanco alrededor de los nombres de intenciones en la columna 'Nombre de la intención'.\n",
    "rules_mos = mos['Nombre de la intención'].str.strip().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos mensajes seguidos de boti\n",
    "\n",
    "# Reinicia los índices del DataFrame 'mm1', descartando los índices anteriores y aplicando los cambios en el lugar.\n",
    "mm1.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Crea una lista 'drop' que contiene los índices de las filas que deben eliminarse.\n",
    "drop = [i if mm1.loc[i].msg_from == mm1.loc[i+1].msg_from and mm1.loc[i].session_id == mm1.loc[i+1].session_id else None for i in mm1.index[:-1]]\n",
    "\n",
    "# Convierte la lista 'drop' en un conjunto para eliminar duplicados y luego convierte de nuevo a lista.\n",
    "drop = list(set(drop))\n",
    "\n",
    "# Elimina los valores 'None' de la lista 'drop'.\n",
    "drop.remove(None)\n",
    "\n",
    "# Elimina las filas del DataFrame 'mm1' utilizando los índices almacenados en la lista 'drop'.\n",
    "mm1.drop(drop, inplace=True)\n",
    "\n",
    "# Reinicia los índices del DataFrame 'mm1' después de eliminar las filas, descartando los índices anteriores y aplicando los cambios en el lugar.\n",
    "mm1.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona las filas en el DataFrame 'mm1' donde la columna 'max_score' no es nula y muestra las primeras filas.\n",
    "mm1[~mm1['max_score'].isnull()].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 del debbug\n",
    "# Análisis de respuestas por usuario en el DataFrame 'mm1':\n",
    "\n",
    "\n",
    "# Copia y reinicia los índices del DataFrame 'mm1'.\n",
    "#mm = mm1.copy()\n",
    "#mm.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Filtra y selecciona columnas específicas de mensajes de texto enviados por usuarios.\n",
    "#mmtex1 = mm[np.logical_and(mm.msg_from == 'user', mm.message_type == 'Text')][['session_id', 'id', 'creation_time', 'msg_from', 'message_type', 'message', 'usuario']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: imprimir dimensiones y verificación paso a paso\n",
    "\n",
    "# 1. Verificar las dimensiones de los DataFrames mm y mmtex1\n",
    "#print(f\"Dimensiones de mm: {mm.shape}\")\n",
    "#print(f\"Dimensiones de mmtex1: {mmtext1.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Definir el rango válido para asegurar que no se excedan los índices de 'mm'\n",
    "#valid_range = mmtex1.index[mmtex1.index + 1 < mm.shape[0]]\n",
    "\n",
    "# Imprimir el rango válido\n",
    "#print(f\"Valid range: {valid_range}\")\n",
    "#print(f\"Longitud del valid_range: {len(valid_range)}\")\n",
    "\n",
    "\n",
    "# 3. Verificar que no haya valores nulos en las columnas de interés dentro de los índices válidos\n",
    "#valid_data_mm = (\n",
    " #   ~mm.loc[valid_range + 1,'rule_name'].isnull() &\n",
    " #   ~mm.loc[valid_range + 1,'session_id'].isnull() &\n",
    " #   ~mm.loc[valid_range + 1,'msg_from'].isnull()\n",
    "#)\n",
    "\n",
    "\n",
    "# Imprimir información de los datos válidos\n",
    "#print(f\"valid_data_mm (True/False array): {valid_data_mm}\")\n",
    "#print(f\"valid_data_mmtex1 (True/False array): {valid_data_mmtex1}\")\n",
    "\n",
    "# 4. Unir las dos máscaras para asegurar que estamos trabajando solo con datos válidos en ambos DataFrames\n",
    "#valid_data = valid_data_mm & valid_data_mmtex1\n",
    "\n",
    "# Imprimir la máscara combinada y verificar su longitud\n",
    "#print(f\"valid_data combinada (True/False array): {valid_data}\")\n",
    "#print(f\"Longitud de valid_data combinada: {len(valid_data)}\")\n",
    "\n",
    "# 5. Filtrar el rango de índices basado en los datos válidos\n",
    "#filtered_range = valid_range[valid_data]\n",
    "\n",
    "# Imprimir el rango filtrado\n",
    "#print(f\"Filtered range: {filtered_range}\")\n",
    "#print(f\"Longitud del filtered_range: {len(filtered_range)}\")\n",
    "\n",
    "# 6. Verificar las dimensiones de las listas que se usarán con zip\n",
    "#print(f\"Longitud de mm.loc[filtered_range + 1].rule_name.values: {len(mm.loc[filtered_range + 1].rule_name.values)}\")\n",
    "#print(f\"Longitud de mmtex1.loc[filtered_range].session_id.values: {len(mmtex1.loc[filtered_range].session_id.values)}\")\n",
    "#print(f\"Longitud de mm.loc[filtered_range + 1].session_id.values: {len(mm.loc[filtered_range + 1].session_id.values)}\")\n",
    "#print(f\"Longitud de mm.loc[filtered_range + 1].msg_from.values: {len(mm.loc[filtered_range + 1].msg_from.values)}\")\n",
    "\n",
    "# 7. Recorrer los valores filtrados y ver los datos\n",
    "#for idx, (r, su, sb, f) in enumerate(zip(\n",
    "#    mm.loc[filtered_range + 1].rule_name.values,\n",
    "#    mmtex1.loc[filtered_range].session_id.values,\n",
    "#    mm.loc[filtered_range + 1].session_id.values,\n",
    "#   mm.loc[filtered_range + 1].msg_from.values\n",
    "#)):\n",
    "    # Imprimir los valores y sus índices correspondientes para depuración\n",
    " #   print(f\"Índice: {filtered_range[idx]}, r: {r}, su: {su}, sb: {sb}, f: {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2.1 del debbug\n",
    "# Crea la columna 'rule_name' basada en ciertas condiciones.\n",
    "#mmtex1['rule_name'] = [r if su == sb and f == 'bot' else None for r, su, sb, f in zip(mm.loc[mmtex1.index + 1].rule_name.values, mmtex1.session_id.values, mm.loc[mmtex1.index + 1].session_id.values, mm.loc[mmtex1.index + 1].msg_from.values)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Nuevo Primera Instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de respuestas por usuario en el DataFrame 'mm1':\n",
    "\n",
    "\n",
    "# Copia y reinicia los índices del DataFrame 'mm1'.\n",
    "mm = mm1.copy()\n",
    "mm.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Filtra y selecciona columnas específicas de mensajes de texto enviados por usuarios.\n",
    "mmtex1 = mm[np.logical_and(mm.msg_from == 'user', mm.message_type == 'Text')][['session_id', 'id', 'creation_time', 'msg_from', 'message_type', 'message', 'usuario']]\n",
    "\n",
    "# Elimina la última fila del DataFrame\n",
    "mmtex1 = mmtex1.iloc[:-1]\n",
    "\n",
    "# Crea la columna 'rule_name' basada en ciertas condiciones.\n",
    "mmtex1['rule_name'] = [r if su == sb and f == 'bot' else None for r, su, sb, f in zip(mm.loc[mmtex1.index + 1].rule_name.values, mmtex1.session_id.values, mm.loc[mmtex1.index + 1].session_id.values, mm.loc[mmtex1.index + 1].msg_from.values)]\n",
    "\n",
    "# Filtra y selecciona las filas relacionadas con la regla 'No entendió letra no existente en WA'.\n",
    "letra1 = mmtex1[mmtex1.rule_name == 'No entendió letra no existente en WA']\n",
    "letra1.rename(columns={'id': 'message_id'}, inplace=True)\n",
    "\n",
    "# Filtra 'search' y 'os' según 'mm1.session_id.values'.\n",
    "search1 = search[search.session_id.isin(mm1.session_id.values)]\n",
    "os1 = os[os.session_id.isin(mm1.session_id.values)]\n",
    "\n",
    "# Filtra las instancias iniciales que no están en 'search1' o 'os1' y realiza algunas transformaciones.\n",
    "primera_instancia1 = search[~search.message_id.isin(pd.concat([search1['RuleBuilder:' + search1.mostrado == search1.response_intent_id].message_id, os1.message_id]).values)].drop_duplicates('id')\n",
    "primera_instancia1.rename(columns={\"results_score\": \"score\"}, inplace=True)\n",
    "ne1 = primera_instancia1.groupby('id').max()[['session_id', 'message_id', 'score']]\n",
    "ne1 = ne1[ne1.score <= 5.36]\n",
    "\n",
    "primera_instancia1 = primera_instancia1[~primera_instancia1.id.isin(ne1.index)]\n",
    "os1 = os1.drop_duplicates('id')[['session_id', 'message_id']]\n",
    "click1 = search1['RuleBuilder:' + search1.mostrado == search1.response_intent_id].drop_duplicates('id')[['session_id', 'message_id']]\n",
    "abandonos1 = primera_instancia1[primera_instancia1.response_message.isna()][['session_id', 'message_id']]\n",
    "nada1 = primera_instancia1[primera_instancia1.response_intent_id == 'RuleBuilder:PLBWX5XYGQ2B3GP7IN8Q-alfafc@gmail.com-1536777380652'][['session_id', 'message_id']]\n",
    "texto1 = primera_instancia1[np.logical_and(primera_instancia1.response_intent_id != 'RuleBuilder:PLBWX5XYGQ2B3GP7IN8Q-alfafc@gmail.com-1536777380652', ~primera_instancia1.response_message.isna())][['session_id', 'message_id']]\n",
    "letra1 = letra1[['session_id', 'message_id']]\n",
    "\n",
    "# Agrega una columna 'categoria' a 'os1', 'click1', 'abandonos1', 'nada1', 'texto1', 'ne1', y 'letra1'.\n",
    "os1['categoria'] = 'one'\n",
    "click1['categoria'] = 'click'\n",
    "abandonos1['categoria'] = 'abandono'\n",
    "nada1['categoria'] = 'nada'\n",
    "texto1['categoria'] = 'texto'\n",
    "ne1['categoria'] = 'ne'\n",
    "letra1['categoria'] = 'letra'\n",
    "\n",
    "\n",
    "# Concatena y filtra 'value1primera' según 'mm1.usuario.values'.\n",
    "value1primera = pd.concat([os1, click1, abandonos1, nada1, texto1, ne1, letra1])\n",
    "value1primera['usuario'] = value1primera.session_id.str[:20]\n",
    "value1primera = value1primera[value1primera.usuario.isin(mm1.usuario.values)]\n",
    "\n",
    "# Realiza un análisis de respuestas por usuario y categoría.\n",
    "respuestas_por_usuario = value1primera.groupby(['usuario', 'categoria'], as_index=False).count()[['usuario', 'categoria', 'message_id']].pivot_table('message_id', ['usuario'], 'categoria')\n",
    "respuestas_por_usuario.fillna(0, inplace=True)\n",
    "respuestas_por_usuario = respuestas_por_usuario.reset_index(drop=False).reindex(['usuario', 'one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra'], axis=1)\n",
    "\n",
    "# Calcula porcentajes por categoría para cada usuario.\n",
    "respuestas_por_usuario['porcentaje_abandono']=[respuestas_por_usuario.loc[i].abandono / respuestas_por_usuario.loc[i][['one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra']].sum() for i in respuestas_por_usuario.index]\n",
    "respuestas_por_usuario['porcentaje_click']=[respuestas_por_usuario.loc[i].click / respuestas_por_usuario.loc[i][['one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra']].sum() for i in respuestas_por_usuario.index]\n",
    "respuestas_por_usuario['porcentaje_one']=[respuestas_por_usuario.loc[i].one / respuestas_por_usuario.loc[i][['one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra']].sum() for i in respuestas_por_usuario.index]\n",
    "respuestas_por_usuario['porcentaje_texto']=[respuestas_por_usuario.loc[i].texto / respuestas_por_usuario.loc[i][['one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra']].sum() for i in respuestas_por_usuario.index]\n",
    "respuestas_por_usuario['porcentaje_nada']=[respuestas_por_usuario.loc[i].nada / respuestas_por_usuario.loc[i][['one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra']].sum() for i in respuestas_por_usuario.index]\n",
    "respuestas_por_usuario['porcentaje_ne']=[respuestas_por_usuario.loc[i]['ne'] / respuestas_por_usuario.loc[i][['one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra']].sum() for i in respuestas_por_usuario.index]\n",
    "respuestas_por_usuario['porcentaje_letra']=[respuestas_por_usuario.loc[i]['letra'] / respuestas_por_usuario.loc[i][['one', 'click', 'texto', 'abandono', 'nada', 'ne', 'letra']].sum() for i in respuestas_por_usuario.index]\n",
    "\n",
    "\n",
    "# Crea un DataFrame 'res_primera_instancia1' basado en 'respuestas_por_usuario'.\n",
    "res_primera_instancia1 = respuestas_por_usuario.copy()\n",
    "\n",
    "# Calcula promedios para diferentes categorías.\n",
    "promedios1={'abandonos': round(respuestas_por_usuario['porcentaje_abandono'].mean(), 3),     \n",
    "                  'click': round(respuestas_por_usuario['porcentaje_click'].mean(), 3),\n",
    "                  'one': round(respuestas_por_usuario['porcentaje_one'].mean(), 3),\n",
    "                  'texto': round(respuestas_por_usuario['porcentaje_texto'].mean(), 3),\n",
    "                  'nada': round(respuestas_por_usuario['porcentaje_nada'].mean(), 3),\n",
    "                  'letra': round(respuestas_por_usuario['porcentaje_letra'].mean(), 3),\n",
    "                  'ne': round(respuestas_por_usuario['porcentaje_ne'].mean(), 3)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_sessions1 = len(mm)\n",
    "print(\"cant_sessions1:\", cant_sessions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_oss1 = len(os1)\n",
    "print(\"cant_oss1:\", cant_oss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne2 = primera_instancia1.groupby('id').max()[['session_id', 'message_id', 'score']]\n",
    "ne2 = ne1[ne1.score <= 5.36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descarga df con las session_id de los casos que se necesiten [En primera instancia]\n",
    "\n",
    "#categoria = {\n",
    "#    'one': os1['session_id'].head(50), [(nada.session_id.creation_time('2024-09-01' between '2024-09-01'))]\n",
    "#    'click': click1['session_id'].head(50),\n",
    "#    'abandono': abandonos1['session_id'].head(50),\n",
    "#   'nada': nada1['session_id'].head(50),\n",
    "#    'texto': texto1['session_id'].head(50),\n",
    "#    'ne': ne1['session_id'],\n",
    "#    'letra': letra1['session_id'].head(50)\n",
    "#}\n",
    "\n",
    "# Guarda cada categoría en un archivo CSV\n",
    "#for categoria, session_ids in categoria.items():\n",
    "#    session_ids.to_csv(f'{categoria}_sessionn_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la funcion que identifica las distintas categorías\n",
    "\n",
    "def categoria(m, t, r):\n",
    "    # Esta función categoriza mensajes basándose en el contenido del mensaje (m), el tipo de mensaje (t), y el nombre de la regla (r).\n",
    "\n",
    "    try:\n",
    "        # Verifica si el tipo de mensaje es 'Button-click' y si el mensaje contiene 'Cambiar de tema'.\n",
    "        if t == 'Button-click' and 'Cambiar de tema' in m:\n",
    "            return 'cambiar'\n",
    "\n",
    "        # Verifica si el tipo de mensaje es 'Button-click' y si la regla es 'Menú show buttons'.\n",
    "        elif t == 'Button-click' and r == 'Menú show buttons':\n",
    "            return 'otros'\n",
    "\n",
    "        # Verifica si el tipo de mensaje es 'Button-click' y si el mensaje contiene 'No era nada de eso'.\n",
    "        elif t == 'Button-click' and 'No era nada de eso' in m:\n",
    "            return 'x'\n",
    "\n",
    "        # Verifica si el tipo de mensaje es 'Button-click'.\n",
    "        elif t == 'Button-click':\n",
    "            return 'boton'\n",
    "\n",
    "        # Verifica si el mensaje es 'a', 'b', 'c', o 'd' (ignorando mayúsculas y minúsculas) y si la regla es 'Infracciones * Apertura'.\n",
    "        elif re.match(r'^a$|^b$|^c$|^d$', m, re.IGNORECASE) and r == 'Infracciones * Apertura':\n",
    "            return 'boton'\n",
    "\n",
    "        # Verifica si el mensaje es 'a', 'b', 'c', o 'd' (ignorando mayúsculas y minúsculas) y si la regla es 'Busca donde está permitido estacionar'.\n",
    "        elif re.match(r'^a$|^b$|^c$|^d$', m, re.IGNORECASE) and r == 'Busca donde está permitido estacionar':\n",
    "            return 'boton'\n",
    "\n",
    "        elif m == '__image__' and r == 'Denuncia Vial - Validación Vehículo':\n",
    "             return 'boton'\n",
    "        elif re.match(r'[0-9]{7,8}', m) and r == 'Licencia prorroga  > Consultar':\n",
    "             return 'boton'\n",
    "\n",
    "        # Verifica si el mensaje es 'x' (ignorando mayúsculas y minúsculas) o 'x buscaba otra cosa'.\n",
    "        elif re.match(r'(^x$)|(x?\\.? ?buscaba otra cosa)', m, re.IGNORECASE):\n",
    "            return 'x'\n",
    "\n",
    "        # Si no coincide con ninguna de las condiciones anteriores, categoriza como 'texto'.\n",
    "        else:\n",
    "            return 'texto'\n",
    "\n",
    "    except:\n",
    "        # Maneja excepciones y retorna 'otros' en caso de error.\n",
    "        return 'otros'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de interacciones del usuario en el DataFrame 'mm1':\n",
    "\n",
    "# Copia el DataFrame 'mm1' a 'mm'.\n",
    "mm = mm1.copy()\n",
    "\n",
    "# Reinicia los índices de 'mm', descartando los índices anteriores y aplicando los cambios en el lugar.\n",
    "mm.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Filtra las filas donde 'msg_from' es 'user'.\n",
    "mmu = mm[mm.msg_from == 'user']\n",
    "\n",
    "# Reinicia los índices de 'mmu', descartando los índices anteriores y aplicando los cambios en el lugar.\n",
    "mmu.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Filtra las filas originales del usuario que están en 'searchcl.message_id'.\n",
    "original = mmu[mmu.id.isin(searchcl.message_id.values)] \n",
    "\n",
    "# Obtiene las filas siguientes (botones) y respuestas subsiguientes.\n",
    "boton = mmu.loc[original.index + 1]\n",
    "respuesta = mmu.loc[original.index + 2]\n",
    "\n",
    "# Crea un DataFrame 'conv_cl' con información de la conversación, como la sesión, la hora de creación y mensajes originales.\n",
    "# También incluye información sobre el intent, el primer botón, respuestas intermedias y finales.\n",
    "conv_cl = pd.DataFrame(data={'session_id': original.session_id.values, 'creation_time': original.creation_time.values, 'original': original.message.values, \n",
    "                             'intent': mm.loc[mm[mm.id.isin(boton.id.values)].index + 1].rule_name.values,\n",
    "                             'bot1_id': [m if v else None for m, v in zip(mm.loc[mm[mm.id.isin(boton.id.values)].index + 1].id.values, original.session_id.values==mm.loc[mm[mm.id.isin(boton.id.values)].index + 1].session_id.values)],\n",
    "                             'respuesta_intermedia': [m if v else None for m, v in zip(boton.message.values, original.session_id.values==boton.session_id.values)], \n",
    "                             'respuesta': [m if v else None for m, v in zip(respuesta.message.values, original.session_id.values==respuesta.session_id.values)],\n",
    "                             'respuesta_type': [m if v else None for m, v in zip(respuesta.message_type.values, original.session_id.values==respuesta.session_id.values)],\n",
    "                             'respuesta_rule': [m if v else None for m, v in zip(mm.loc[mm[mm.id.isin(respuesta.id.values)].index + 1].rule_name.values, original.session_id.values==mm.loc[mm[mm.id.isin(respuesta.id.values)].index + 1].session_id.values)]})\n",
    "\n",
    "mm = mm1.copy()\n",
    "mm.reset_index(inplace=True, drop=True)\n",
    "mmu = mm[mm.msg_from == 'user']\n",
    "mmu.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Filtra las filas originales del usuario que están en 'os.message_id'.\n",
    "original = mmu[mmu.id.isin(os.message_id.values)]\n",
    "\n",
    "# Obtiene la respuesta subsiguiente.\n",
    "respuesta = mmu.loc[original.index + 1]\n",
    "\n",
    "# Crea un DataFrame 'conv' con información de la conversación, como la sesión, la hora de creación y mensajes originales.\n",
    "# También incluye información sobre el intent, el primer botón, y respuestas subsiguientes.\n",
    "conv = pd.DataFrame(data={'session_id': original.session_id.values, 'creation_time': original.creation_time.values, 'original': original.message.values, \n",
    "                          'intent': mm.loc[mm[mm.id.isin(original.id.values)].index + 1].rule_name.values,\n",
    "                          'bot1_id': [m if v else None for m, v in zip(mm.loc[mm[mm.id.isin(original.id.values)].index + 1].id.values, original.session_id.values==mm.loc[mm[mm.id.isin(original.id.values)].index + 1].session_id.values)],\n",
    "                          'respuesta': [m if v else None for m, v in zip(respuesta.message.values, original.session_id.values==respuesta.session_id.values)],\n",
    "                          'respuesta_type': [m if v else None for m, v in zip(respuesta.message_type.values, original.session_id.values==respuesta.session_id.values)],\n",
    "                          'respuesta_rule': [m if v else None for m, v in zip(mm.loc[mm[mm.id.isin(respuesta.id.values)].index + 1].rule_name.values, original.session_id.values==mm.loc[mm[mm.id.isin(respuesta.id.values)].index + 1].session_id.values)]})\n",
    "\n",
    "\n",
    "# Crea una nueva columna 'categoria' en 'conv' utilizando la función 'categoria'.\n",
    "conv['categoria'] = [categoria(m, t, r) if m is not None else 'abandono' for m, t, r in zip(conv.respuesta, conv.respuesta_type, conv.intent)]\n",
    "\n",
    "# Agrupa por 'categoria' y cuenta la cantidad de 'bot1_id' para cada categoría.\n",
    "per = conv.groupby('categoria', as_index=False).count()[['categoria', 'bot1_id']]\n",
    "\n",
    "# Calcula el porcentaje de cada categoría respecto al total.\n",
    "per['per'] = per.bot1_id / per.bot1_id.sum()\n",
    "\n",
    "# Concatena 'conv_cl' y 'conv' en un nuevo DataFrame 'usuario1', y agrega columnas adicionales.\n",
    "usuario1 = pd.concat([conv_cl[['session_id', 'creation_time', 'original', 'intent', 'bot1_id', 'respuesta', 'respuesta_type', 'respuesta_rule']], conv])\n",
    "\n",
    "# Crea una nueva columna 'categoria' en 'usuario1' utilizando la función 'categoria'.\n",
    "usuario1['categoria'] = [categoria(m, t, r) if m is not None else 'abandono' for m, t, r in zip(usuario1.respuesta, usuario1.respuesta_type, usuario1.intent)]\n",
    "\n",
    "# Crea una nueva columna 'usuario' en 'usuario1' extrayendo los primeros 20 caracteres de 'session_id'.\n",
    "usuario1['usuario'] = usuario1.session_id.str[:20]\n",
    "\n",
    "# Crea una nueva columna 'id' en 'usuario1' copiando los valores de 'bot1_id'.\n",
    "usuario1['id'] = usuario1.bot1_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_sessions2 = len(mmu)\n",
    "print(\"cant_sessions2:\", cant_sessions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de resultados por usuario:\n",
    "\n",
    "resultados=[]\n",
    "promedios=[]\n",
    "\n",
    "# Itera sobre el DataFrame 'usuario1'.\n",
    "for usuario in [usuario1]:\n",
    "\n",
    "    # Agrupa por 'usuario' y 'categoria', y cuenta la cantidad de 'id' para cada categoría.\n",
    "    respuestas_por_usuario=usuario.groupby(['usuario','categoria'], as_index=False).count()[['usuario','categoria', 'id']].pivot_table('id', ['usuario'], 'categoria')\n",
    "    respuestas_por_usuario.fillna(0, inplace=True)\n",
    "\n",
    "    # Reordena las columnas del DataFrame 'respuestas_por_usuario'.\n",
    "    respuestas_por_usuario=respuestas_por_usuario.reset_index(drop=False).reindex(['usuario', 'abandono', 'boton', 'otros', 'texto', 'x', 'cambiar'], axis=1)\n",
    "\n",
    "    # Calcula los porcentajes para cada categoría.\n",
    "    respuestas_por_usuario['porcentaje_abandono']=[respuestas_por_usuario.loc[i].abandono / respuestas_por_usuario.loc[i][['abandono', 'boton', 'otros', 'texto', 'x',  'cambiar']].sum() for i in respuestas_por_usuario.index]\n",
    "    respuestas_por_usuario['porcentaje_boton']=[respuestas_por_usuario.loc[i].boton / respuestas_por_usuario.loc[i][['abandono', 'boton', 'otros', 'texto', 'x',  'cambiar']].sum() for i in respuestas_por_usuario.index]\n",
    "    respuestas_por_usuario['porcentaje_otros']=[respuestas_por_usuario.loc[i].otros / respuestas_por_usuario.loc[i][['abandono', 'boton', 'otros', 'texto', 'x',  'cambiar']].sum() for i in respuestas_por_usuario.index]\n",
    "    respuestas_por_usuario['porcentaje_texto']=[respuestas_por_usuario.loc[i].texto / respuestas_por_usuario.loc[i][['abandono', 'boton', 'otros', 'texto', 'x',  'cambiar']].sum() for i in respuestas_por_usuario.index]\n",
    "    respuestas_por_usuario['porcentaje_x']=[respuestas_por_usuario.loc[i].x / respuestas_por_usuario.loc[i][['abandono', 'boton', 'otros', 'texto', 'x',  'cambiar']].sum() for i in respuestas_por_usuario.index]\n",
    "    respuestas_por_usuario['porcentaje_cambiar']=[respuestas_por_usuario.loc[i].cambiar / respuestas_por_usuario.loc[i][['abandono', 'boton', 'otros', 'texto', 'x',  'cambiar']].sum() for i in respuestas_por_usuario.index]\n",
    "\n",
    "    # Agrega el DataFrame 'respuestas_por_usuario' a la lista 'resultados'.\n",
    "    resultados.append(respuestas_por_usuario)\n",
    "\n",
    "    # Calcula los promedios de porcentajes para cada categoría y agrega a la lista 'promedios'.\n",
    "    promedios.append({'abandonos': round(respuestas_por_usuario['porcentaje_abandono'].mean(), 3),     \n",
    "                      'botones': round(respuestas_por_usuario['porcentaje_boton'].mean(), 3),\n",
    "                      'otros': round(respuestas_por_usuario['porcentaje_otros'].mean(), 3),\n",
    "                      'texto': round(respuestas_por_usuario['porcentaje_texto'].mean(), 3),\n",
    "                      'x': round(respuestas_por_usuario['porcentaje_x'].mean(), 3),\n",
    "                      'cambiar de tema': round(respuestas_por_usuario['porcentaje_cambiar'].mean(), 3)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#casos_x = respuestas_por_usuario['porcentaje_x']=[respuestas_por_usuario.loc[i]].x \n",
    "#casos_x = respuestas_por_usuario[['usuario', 'x']]\n",
    "# Extrae los valores crudos de la columna 'x' y los agrega a la lista 'valores_x'.\n",
    "#casos_x.extend(respuestas_por_usuario['x'].values)\n",
    "\n",
    "# 'valores_x' ahora contiene los valores crudos de 'x' para cada usuario.\n",
    "#print(casos_x)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "#casos_x.to_csv('casos_x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos el DataFrame para obtener las sesiones con la columna 'x'\n",
    "#sesiones_botones = respuestas_por_usuario[['usuario', 'boton']]\n",
    "#sesiones_x = respuestas_por_usuario[['x']]\n",
    "# Si deseas incluir solo las sesiones donde 'x' tenga valores mayores a 0\n",
    "# sesiones_x = sesiones_x[sesiones_x['x'] > 0]\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "#sesiones_x.to_csv('sesiones_x.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(promedios, index=['nuevo-con-oss', 'nuevo-sin-oss'])[['abandonos', 'botones', 'texto', 'x', 'cambiar de tema', 'otros']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un nuevo diccionario 'con_oss1' multiplicando cada valor en 'promedios1' por 100.\n",
    "con_oss1 = {k: v * 100 for k, v in promedios1.items()}\n",
    "\n",
    "# Crea un nuevo diccionario 'con_oss2' multiplicando los valores correspondientes en 'promedios1' por las sumas ponderadas de 'click' y 'one' en 'promedios'.\n",
    "con_oss2 = {k: (promedios1['click'] + promedios1['one']) * v * 100 for k, v in promedios[0].items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_oss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_oss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_oss1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
